# Bosch-Motors-Dataset
This project is my master thesis and also a sub-project of the research project AgiProbot from KIT and Bosch. We develop a benchmark including 2D synthetic image datasets and 3D synthetic point cloud datasets, in which the key objects have multiple learn-able attributes with ground truth provided. In this project, small electric motors are used as the key objects.
## Datasets Preparation
### 1. Motor Mesh Dataset
We generate 5 kinds of synthetic motor mesh with Blender addon named [Motor Factory](https://github.com/cold-soda-jay/blenderMotorFactoryVer2.0) in randomly different size ranges in each motor's parts. In the demo, I generated 10 of each type of motor, 50 in total. We also model the clamping system in Blender and make it look more realistic by changing its texture material. We import one motor and merge it with the clamping system in each scene.
### 2. Images Dataset 
The generation of image dataset is with the help of the [Blenderproc](https://github.com/DLR-RM/BlenderProc). In the image dataset, we generated 5 images for each scene, which are RGB-image, depth-image, normal-image, semantic segmentated image for each part of the motor and a COCO-annotated image with a 2D bounding box of the motor, for the following tasks of the main project, we also add the 2D bounding box of the bolts. In each scene, we changed the position and euler rotation of the camera to increase the diversity of the scene. At the same time, we also randomly rotated the motor a little bit to simulate the improper placement of the motor in reality. This information will be saved in the csv file named camera_motor_setting.csv.
### 3. Point Cloud Dataset
After generated the image dataset, we use another Blender addon named [Blensor](https://www.blensor.org/) to generate the point cloud dataset of each scene. In order to maintain correspondence with the image dataset, we use the corresponding camera information saved in the camera_motor_setting.csv to capture the scene in point cloud. We mark the position of the motor in the point cloud scene with a 3D bounding box, and save the three-dimensional coordinates of the center of each motor and the length, width and height of the entire motor in motor_3D_bounding_box.csv for the deep learning task of 3D object detection. As we set the resolution of each scene to 1280x960, which is 1228800 points, and the motor occupies only more than 40000 points. In order to improve the deep learning efficiency, we cut out a cuboid with the motor as the center. We provide each motor with both scene and cuboid point cloud in Numpy and PCD format.
