# Bosch-Motors-Dataset
This project is my master thesis and also a sub-project of the research project AgiProbot from KIT and Bosch. We develop a benchmark including 2D synthetic image datasets and 3D synthetic point cloud datasets, in which the key objects have multiple learn-able attributes with ground truth provided. In this project, small electric motors are used as the key objects. This part explains how to generate the datasets, including motor mesh model dataset, image dataset, point cloud dataset and noise point cloud dataset. We also build a synthetic clamping system with Blender to simulate the motor being clamped by the fixture in the real scenario.
## Software Preparation
As our programming is based on the python language, we recommend a [Python>=3.7.0](https://www.python.org/) environment, including [Numpy](https://numpy.org/)
We use [Blender 2.9](https://www.blender.org/) to generate the synthetic motor mesh model with the addon named motor factory. For specific details including how to install, you can see [Motor Factory](https://github.com/cold-soda-jay/blenderMotorFactoryVer2.0). 
### 1. Motor Mesh Model Dataset
We generate 5 kinds of synthetic motor mesh with Blender addon in randomly different size ranges in each motor's parts. Run the Blender(version 2.9 above is recommended), open Text Editor(hotkey: Shift + F11) and open the script named synthetic_motor_generate.py. You should specify the path to save in BASE_DIR and the number of the motors in main() function.(In the demo, I generated 10 of each type of motor, 50 in total.) 
```python
BASE_DIR = '/home/linxi/KIT/Thesis/Dataset/motor_mesh_model_50/'
num_motor_for_dataset=50
```
### 2. Image Dataset 
The generation of image dataset is with the help of the [Blenderproc](https://github.com/DLR-RM/BlenderProc). In the image dataset, we generated 5 images for each scene, which are RGB-image, depth-image, normal-image, semantic segmentated image for each part of the motor and a COCO-annotated image with a 2D bounding box of the motor, for the following tasks of the main project, we also add the 2D bounding box of the bolts. In each scene, we changed the position and euler rotation of the camera to increase the diversity of the scene. At the same time, we also randomly rotated the motor a little bit to simulate the improper placement of the motor in reality. This information will be saved in the csv file named camera_motor_setting.csv.
### 3. Point Cloud Dataset
After generated the image dataset, we use another Blender addon named [Blensor](https://www.blensor.org/) to generate the point cloud dataset of each scene. In order to maintain correspondence with the image dataset, we use the corresponding camera information saved in the camera_motor_setting.csv to capture the scene in point cloud. We mark the position of the motor in the point cloud scene with a 3D bounding box, and save the three-dimensional coordinates of the center of each motor and the length, width and height of the entire motor in motor_3D_bounding_box.csv for the deep learning task of 3D object detection. As we set the resolution of each scene to 1280x960, which is 1228800 points, and the motor occupies only more than 40000 points. In order to improve the deep learning efficiency, we cut out a cuboid with the motor as the center. We provide each motor with both scene and cuboid point cloud in Numpy and PCD format.
### 4. Noise Point Cloud Dataset
